---
title: "Principle Component Aanalysis"
output: html_document
---
## Data
The data you will be using comes from the Assistments online intelligent tutoring system (https://www.assistments.org/). It describes students working through online math problems. Each student has the following data associated with them:

- id
- prior_prob_count: How many problems a student has answered in the system prior to this session
- prior_percent_correct: The percentage of problems a student has answered correctly prior to this session
- problems_attempted: The number of problems the student has attempted in the current session
- mean_correct: The average number of correct answers a student made on their first attempt at problems in the current session
- mean_hint: The average number of hints a student asked for in the current session
- mean_attempt: The average number of attempts a student took to answer a problem in the current session
- mean_confidence: The average confidence each student has in their ability to answer the problems in the current session

## Start by uploading the data
```{r}
D1 <- read.csv("Assistments-confidence.csv", header = T)
D1 <- D1[, -1]

  #We won't need the id variable, so remove that.


```

## Create a correlation matrix of the relationships between the variables, including correlation coefficients for each pair of variables/features.

```{r}
#You can install the corrplot package to plot some pretty correlation matrices (sometimes called correlograms)

library(corrplot)

#Generate pairwise correlations
COR <- cor(D1)

corrplot(COR, order="AOE", method="circle", tl.pos="lt", type="upper",        
tl.col="black", tl.cex=0.6, tl.srt=45, 
        addCoef.col="black", addCoefasPercent = TRUE,
        sig.level=0.50, insig = "blank")

#Study your correlogram image and save it, you will need it later
```

## Create a new data frame with the mean_correct variables removed

```{r}
D2 <- D1[, c(1:3, 5:7)]

#The, scale and center your data for easier interpretation
D2 <- scale(D2, center = TRUE)
```

## Now run the PCA on the new data frame

```{r}
pca <- prcomp(D2, scale = TRUE)
```

## Although princomp does not generate the eigenvalues directly for us, we can print a list of the standard deviation of the variance accounted for by each component.

```{r}
pca$sdev

#To convert this into variance accounted for we can square it, these numbers are proportional to the eigenvalue

pca$sdev^2

#A summary of our pca will give us the proportion of variance accounted for by each component

summary(pca)

#We can look at this to get an idea of which components we should keep and which we should drop

plot(pca, type = "lines")
```

## Think about which components you would drop and make a decision

## Part II

```{r}
#Now, create a data frame of the transformed data from your pca.

D3 <- as.data.frame(pca$x)

#Attach the variable "mean_correct" from your original data frame to D3.

D4 <- cbind(D3, as.data.frame(D1$mean_correct))

#Now re-run your scatterplots and correlations between the transformed data and mean_correct. If you had dropped some components would you have lost important infomation about mean_correct?

COR2 <- cor(D4)

```
## Now print out the eigenvectors (often called loadings) for the components you generated:

```{r}
pca$rotation

#Examine the eigenvectors, notice that they are a little difficult to interpret. It is much easier to make sense of them if we make them proportional within each component

loadings <- abs(pca$rotation) #abs() will make all eigenvectors positive

sweep(loadings, 2, colSums(loadings), "/") #sweep() computes each row as a proportion of the column. (There must be a way to do this with dplyr()?)

# Answer to creating this table with dplyr():
library(dplyr)
library(tidyr)
loadings2 <- tbl_df(loadings)
Variables <- c("prior_prob_count", "prior_percent_correct", "problems_attempted", "mean_hint", "mean_attempt", "mean_confidence ") 
loadings3 <- cbind(Variables, loadings2)
loadings4 <- loadings3 %>% mutate(PC1 = PC1/sum(PC1)) %>% mutate(PC2 = PC2/sum(PC2)) %>% mutate(PC3 = PC3/sum(PC3)) %>% mutate(PC4 = PC4/sum(PC4)) %>% mutate(PC5 = PC5/sum(PC5)) %>%  mutate(PC6 = PC6/sum(PC6)) %>% print
 

#Now examine your components and try to come up with substantive descriptions of what some might represent?

# PC1 accounts for the most variance in the three variables: mean_hint, mean_attempt, and problems_attempted. 30.22% of variaion can be explained by the average number of hints a student asked for in the current session, 25.86% of variaion can be explained by the average number of attempts a student took to answer a problem in the current session, and 21.74% of variaion can be explained by the number of problems the student has attempted in the current session. 

# PC2 contributes the most to prior_prob_count, prior_percent_correct, and problems_attempted. 25.08% of variation can be explained by how many problems a student has answered in the system prior to this session, 44.68% of variation can be explained by the percentage of problems a student has answered correctly prior to this session, and 17.34% of variation can be explained by the number of problems the student has attempted in the current session. 

# PC3 contributes the most to prior_prob_count, problems_attempted, and mean_confidence. 22.10% of variation can be explained by how many problems a student has answered in the system prior to this session, 20.06% of variation can be explained by the number of problems the student has attempted in the current session, and 45.79% of variation can be explained by the average confidence each student has in their ability to answer the problems in the current session, which is substantial. 

# PC4 contributes the most only to prior_prob_count and mean_confidence. 31.52% of variation can be explained by how many problems a student has answered in the system prior to this session. And 22.61% of variation can be explained by the average confidence each student has in their ability to answer the problems in the current session.

# PC5 contributes the most only to problems_attempted and mean_attempt. 30.39% of variation can be explained by the number of problems the student has attempted in the current session, and 35.77% of variation can be explained by the average number of attempts a student took to answer a problem in the current session.

# PC6 only contributes the most to mean_hint. 35.61% of variation can be explained by the average number of hints a student asked for in the current session. 

biplot(pca)

#Calculate values for each student that represent these your composite variables and then create a new correlogram showing their relationship to mean_correct.

```
# Part III  
## Also in this repository is a data set and codebook from Rod Martin, Patricia Puhlik-Doris, Gwen Larsen, Jeanette Gray, Kelly Weir at the University of Western Ontario about people's sense of humor. Can you perform a PCA on this data?
```{r}
K1 = read.csv("humor_data.csv")
K1 = K1[ ,1:32]

COR3 = cor(K1)

corrplot(COR3, order = "AOE", method = "circle", tl.pos = "lt", type = "upper",  tl.col = "black", tl.cex = 0.5, addCoef.col = "black", addCoefasPercent = TRUE, sig.level = 0.50, insig = "blank")

K2 = scale(K1, center = TRUE)
PCA = prcomp(K2, scale = TRUE)
plot(PCA, type = "lines")

K3 = as.data.frame(PCA$x)
K3 = K3[,1:5]
biplot(PCA)
# The biplot gives the same result as the research result, and each cluster represents a characteristic from "affiliative", "selfenhancing", "agressive", and "selfdefeating".
```
